{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer\n",
    "import tensorflow as tf\n",
    "from transformers import TFRobertaForSequenceClassification\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.0.0 of praw is outdated. Version 7.1.0 was released Tuesday June 23, 2020.\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id='c61aYydHGTRGkw',\n",
    "                     client_secret='hEw2j00lh_w2inKcTAlcqq_kJT0',\n",
    "                     user_agent='android:com.example.myredditapp:v1.2.3')\n",
    "\n",
    "# get 10 hot posts from the MachineLearning subreddit\n",
    "top_posts = reddit.subreddit('showerthoughts').top('week', limit=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_length = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_to_feature(review):\n",
    "    # combine step for tokenization, WordPiece vector mapping and will\n",
    "    # add also special tokens and truncate reviews longer than our max length\n",
    "    return roberta_tokenizer.encode_plus(review,\n",
    "                                         add_special_tokens=True,\n",
    "                                         max_length=max_length,\n",
    "                                         pad_to_max_length=True,\n",
    "                                         return_attention_mask=True,\n",
    "                                         )\n",
    "\n",
    "\n",
    "# map to the expected input to TFRobertaForSequenceClassification, see here\n",
    "def map_example_to_dict(input_ids, attention_masks, label):\n",
    "    return {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "           }, label\n",
    "\n",
    "\n",
    "def encode_examples(ds, limit=-1):\n",
    "    # Prepare Input list\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    label_list = []\n",
    "\n",
    "    if (limit > 0):\n",
    "        ds = ds.take(limit)\n",
    "\n",
    "    for review, label in tfds.as_numpy(ds):\n",
    "        bert_input = convert_example_to_feature(review.decode())\n",
    "        input_ids_list.append(bert_input['input_ids'])\n",
    "        attention_mask_list.append(bert_input['attention_mask'])\n",
    "        label_list.append([label])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((input_ids_list,\n",
    "                                               attention_mask_list,\n",
    "                                               label_list)).map(map_example_to_dict)\n",
    "\n",
    "\n",
    "def replies_of(top_level_comment, comment_list):\n",
    "    if len(top_level_comment.replies) == 0:\n",
    "        return\n",
    "    else:\n",
    "        for num, comment in enumerate(top_level_comment.replies):\n",
    "            try:\n",
    "                comment_list.append(str(comment.body))\n",
    "            except:\n",
    "                continue\n",
    "            replies_of(comment, comment_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "model = TFRobertaForSequenceClassification.from_pretrained('reddit_model5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_subreddit = ['showerthoughts', 'askmen', 'askreddit', 'jokes', 'worldnews']\n",
    "list_of_subreddit = ['showerthoughts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall sentiment of subreddit r/showerthoughts are Positive comments: Comments    2752\n",
      "label       2752\n",
      "dtype: int64 Negative comments: Comments    8\n",
      "label       8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for j in list_of_subreddit:\n",
    "    # get 10 hot posts from the MachineLearning subreddit\n",
    "    top_posts = reddit.subreddit(j).top('week', limit=10)\n",
    "    comment_list = []\n",
    "    # save subreddit comments in dataframe\n",
    "    for submission in top_posts:\n",
    "        submission_comm = reddit.submission(id=submission.id)\n",
    "\n",
    "        for count, top_level_comment in enumerate(submission_comm.comments):\n",
    "            try:\n",
    "                replies_of(top_level_comment, comment_list)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    comment_dataframe = pd.DataFrame(comment_list, columns=['Comments'])\n",
    "    comment_dataframe['label'] = 0\n",
    "  \n",
    "  \n",
    "    \n",
    "    # prepare data as per RoBERTa model input\n",
    "    submission_sentences_modified = tf.data.Dataset.from_tensor_slices((comment_dataframe['Comments'],\n",
    "                                                                        comment_dataframe['label']))    \n",
    "    \n",
    "    ds_submission_encoded = encode_examples(submission_sentences_modified).batch(batch_size)\n",
    "\n",
    "    \n",
    "    # predict sentiment of Reddit comments\n",
    "    submission_pre = tf.nn.softmax(model.predict(ds_submission_encoded))\n",
    "    submission_pre_argmax = tf.math.argmax(submission_pre, axis=1)\n",
    "    comment_dataframe['label'] = submission_pre_argmax\n",
    "\n",
    "    negative_comments_count = comment_dataframe[comment_dataframe['label'] == 1].count()\n",
    "    positive_comments_count = comment_dataframe[comment_dataframe['label'] == 0].count()\n",
    "\n",
    "    print(f\"overall sentiment of subreddit r/{j} are Positive comments: {positive_comments_count}\"\n",
    "          f\" Negative comments: {negative_comments_count}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3966, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_dataframe.head(50)\n",
    "comment_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>How does cultural appropriation value them as gifts?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>No hate but what’s consent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>This right here, this is the exact rhetoric that Witchifer was talking about. That rhetoric you are using, is exactly how those Youtubers talking about flat-earth and antivaxx start their videos.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>It's also prone to biases, corruption, incompetence and misinterpretation.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>Pseudoscience isn't science though. The scientific consensus supports the validity of trans peoples identities.\\n[https://blogs.scientificamerican.com/voices/stop-using-phony-science-to-justify-transphobia/]()</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>r/thalassophobia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>thalassophobia intensifies...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>Grey-asexual is someone who experiences sexual attraction very rarely, as opposed to a gay asexual who may also be known as a homoromantic asexual.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                               Comments  \\\n",
       "411   How does cultural appropriation value them as gifts?                                                                                                                                                                \n",
       "514   No hate but what’s consent                                                                                                                                                                                          \n",
       "1631  This right here, this is the exact rhetoric that Witchifer was talking about. That rhetoric you are using, is exactly how those Youtubers talking about flat-earth and antivaxx start their videos.                 \n",
       "1730  It's also prone to biases, corruption, incompetence and misinterpretation.                                                                                                                                          \n",
       "1770  Pseudoscience isn't science though. The scientific consensus supports the validity of trans peoples identities.\\n[https://blogs.scientificamerican.com/voices/stop-using-phony-science-to-justify-transphobia/]()   \n",
       "1843  r/thalassophobia                                                                                                                                                                                                    \n",
       "1862  thalassophobia intensifies...                                                                                                                                                                                       \n",
       "2551  Grey-asexual is someone who experiences sexual attraction very rarely, as opposed to a gay asexual who may also be known as a homoromantic asexual.                                                                 \n",
       "\n",
       "      label  \n",
       "411   1      \n",
       "514   1      \n",
       "1631  1      \n",
       "1730  1      \n",
       "1770  1      \n",
       "1843  1      \n",
       "1862  1      \n",
       "2551  1      "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_dataframe[comment_dataframe['label'] == 1].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Right now there is some alien species somewhere who shit gold and trade with poop, wondering the same.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This could be a science fiction novel. I would read the ~~shit~~poop out of it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r/WritingPrompts</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There's already a storyline on American dad that revolve around Roger pooping gold and gems</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>What a ~~country~~ galaxy!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fantastic username, by the way.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Or entire solar systems where every planet is colonized with clams resting in sandy banks with moons populated with trees dripping with sap.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ok but what about space weed.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The spice must flow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                        Comments  \\\n",
       "0   [deleted]                                                                                                                                      \n",
       "1   Right now there is some alien species somewhere who shit gold and trade with poop, wondering the same.                                         \n",
       "2   This could be a science fiction novel. I would read the ~~shit~~poop out of it                                                                 \n",
       "3   r/WritingPrompts                                                                                                                               \n",
       "4   There's already a storyline on American dad that revolve around Roger pooping gold and gems                                                    \n",
       "..                                                                                          ...                                                    \n",
       "95  What a ~~country~~ galaxy!                                                                                                                     \n",
       "96  Fantastic username, by the way.                                                                                                                \n",
       "97  Or entire solar systems where every planet is colonized with clams resting in sandy banks with moons populated with trees dripping with sap.   \n",
       "98  Ok but what about space weed.                                                                                                                  \n",
       "99  The spice must flow                                                                                                                            \n",
       "\n",
       "    label  \n",
       "0   0      \n",
       "1   0      \n",
       "2   0      \n",
       "3   0      \n",
       "4   0      \n",
       ".. ..      \n",
       "95  0      \n",
       "96  0      \n",
       "97  0      \n",
       "98  0      \n",
       "99  0      \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_dataframe[comment_dataframe['label'] == 0].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(negative_comments_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
