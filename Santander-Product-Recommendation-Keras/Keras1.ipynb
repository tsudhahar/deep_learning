{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5105)\n",
      "/home/r/.local/lib/python3.4/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "matplotlib.rcParams['figure.figsize'] = (8, 6)\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demographic_cols = ['ncodpers','fecha_alta','ind_empleado','pais_residencia','sexo','age','ind_nuevo','antiguedad','indrel',\n",
    " 'indrel_1mes','tiprel_1mes','indresi','indext','conyuemp','canal_entrada','indfall',\n",
    " 'tipodom','cod_prov','ind_actividad_cliente','renta','segmento']\n",
    "\n",
    "notuse = [\"ult_fec_cli_1t\",\"nomprov\",'fecha_dato']\n",
    "\n",
    "product_col = [\n",
    " 'ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1',\n",
    " 'ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1',\n",
    " 'ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_plan_fin_ult1',\n",
    " 'ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1','ind_nomina_ult1',\n",
    " 'ind_nom_pens_ult1','ind_recibo_ult1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r/.local/lib/python3.4/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (4,7,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('cleaned_data/DataMulticlass_6_withpast2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r/.local/lib/python3.4/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('cleaned_data/TestSet_withpast3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df_train['fecha_alta'] = df_train['fecha_alta'].apply(lambda x: x.toordinal()-(1990*365))\n",
    "df_test['fecha_alta'] = df_test['fecha_alta'].apply(lambda x: x.toordinal()-(1990*365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_data(df):\n",
    "    df = df[df['ind_nuevo'] == 0]\n",
    "    df = df[df['antiguedad'] != -999999]\n",
    "    df = df[df['indrel'] == 1]\n",
    "    df = df[df['indresi'] == 'S']\n",
    "    df = df[df['indfall'] == 'N']\n",
    "    df = df[df['tipodom'] == 1]\n",
    "    df = df[df['ind_empleado'] == 'N']\n",
    "    df = df[df['pais_residencia'] == 'ES']\n",
    "    df = df[df['indrel_1mes'] == 1]\n",
    "    df = df[df['tiprel_1mes'] == ('A' or 'I')]\n",
    "    df = df[df['indext'] == 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_data(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unneccessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_column = ['ind_nuevo','indrel','indresi','indfall','tipodom','ind_empleado','pais_residencia','indrel_1mes','indext','conyuemp','fecha_alta','tiprel_1mes']\n",
    "\n",
    "df_train.drop(drop_column, axis=1, inplace = True)\n",
    "df_test.drop(drop_column, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test[\"renta\"]   = pd.to_numeric(df_test[\"renta\"], errors=\"coerce\")\n",
    "unique_prov = df_test[df_test.cod_prov.notnull()].cod_prov.unique()\n",
    "grouped = df_test.groupby(\"cod_prov\")[\"renta\"].median()\n",
    "\n",
    "def impute_renta(df):\n",
    "    df[\"renta\"]   = pd.to_numeric(df[\"renta\"], errors=\"coerce\")       \n",
    "    for cod in unique_prov:\n",
    "        df.loc[df['cod_prov']==cod,['renta']] = df.loc[df['cod_prov']==cod,['renta']].fillna({'renta':grouped[cod]}).values\n",
    "    df.renta.fillna(df_test[\"renta\"].median(), inplace=True)\n",
    "    \n",
    "impute_renta(df_train)\n",
    "impute_renta(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drop_na(df):\n",
    "    df.dropna(axis = 0, subset = ['ind_actividad_cliente'], inplace = True)\n",
    "    \n",
    "drop_na(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert and make dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These column are categories feature, I'll transform them using get_dummy\n",
    "dummy_col = ['sexo','canal_entrada','cod_prov','segmento']\n",
    "dummy_col_select = ['canal_entrada','cod_prov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit = int(0.01 * len(df_train.index))\n",
    "use_dummy_col = {}\n",
    "\n",
    "for col in dummy_col_select:\n",
    "    trainlist = df_train[col].value_counts()\n",
    "    use_dummy_col[col] = []\n",
    "    for i,item in enumerate(trainlist):\n",
    "        if item > limit:\n",
    "            use_dummy_col[col].append(df_train[col].value_counts().index[i])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dummy(df):\n",
    "    for col in dummy_col_select:\n",
    "        for item in df[col].unique(): \n",
    "            if item not in use_dummy_col[col]:\n",
    "                row_index = df[col] == item\n",
    "                df.loc[row_index,col] = np.nan\n",
    "    return pd.get_dummies(df, prefix=dummy_col, columns = dummy_col)\n",
    "    \n",
    "df_train = get_dummy(df_train)\n",
    "df_test = get_dummy(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_age(df):\n",
    "    df[\"age\"]   = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "    max_age = 80 \n",
    "    log_max_age = np.log(max_age) \n",
    "    square_max_age  = np.square(max_age)\n",
    "    df[\"age\"]   = df['age'].apply(lambda x: min(x ,max_age))\n",
    "    df[\"log_age\"]   = df['age'].apply(lambda x: round(np.log10(x+1)/log_max_age, 6))\n",
    "    df[\"square_age\"]   = df['age'].apply(lambda x: round(np.square(x)/square_max_age, 6))\n",
    "    df[\"age\"]   = df['age'].apply(lambda x: round( x/max_age, 6))\n",
    "\n",
    "def clean_renta(df):\n",
    "    max_renta = 1.0e6\n",
    "    log_max_renta = np.log(max_renta) \n",
    "    square_max_renta  = np.square(max_renta)\n",
    "    df[\"renta\"]   = df['renta'].apply(lambda x: min(x ,max_renta))\n",
    "    df[\"log_renta\"]   = df['renta'].apply(lambda x: round(np.log10(x+1)/log_max_renta, 6))\n",
    "    df[\"square_renta\"]   = df['renta'].apply(lambda x: round(np.square(x)/square_max_renta, 6))\n",
    "    df[\"renta\"]   = df['renta'].apply(lambda x: round( x/max_renta, 6))\n",
    "    \n",
    "def clean_antigue(df):\n",
    "    df[\"antiguedad\"]   = pd.to_numeric(df[\"antiguedad\"], errors=\"coerce\")\n",
    "    df[\"antiguedad\"] = df[\"antiguedad\"].replace(-999999, df['antiguedad'].median())\n",
    "    max_antigue = 256\n",
    "    log_max_antigue = np.log(max_antigue) \n",
    "    square_max_antigue  = np.square(max_antigue)\n",
    "    df[\"antiguedad\"]   = df['antiguedad'].apply(lambda x: min(x ,max_antigue))\n",
    "    df[\"log_antiguedad\"]   = df['antiguedad'].apply(lambda x: round(np.log10(x+1)/log_max_antigue, 6))\n",
    "    df[\"square_antiguedad\"]   = df['antiguedad'].apply(lambda x: round(np.square(x)/square_max_antigue, 6))\n",
    "    df[\"antiguedad\"]   = df['antiguedad'].apply(lambda x: round( x/max_antigue, 6))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_age(df_train)\n",
    "clean_age(df_test)\n",
    "\n",
    "clean_renta(df_train)\n",
    "clean_renta(df_test)\n",
    "\n",
    "clean_antigue(df_train)\n",
    "clean_antigue(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_col_5 = [col for col in df_train.columns if '_ult1_5' in col]\n",
    "product_col_4 = [col for col in df_train.columns if '_ult1_4' in col]\n",
    "product_col_3 = [col for col in df_train.columns if '_ult1_3' in col]\n",
    "product_col_2 = [col for col in df_train.columns if '_ult1_2' in col]\n",
    "product_col_1 = [col for col in df_train.columns if '_ult1_1' in col]\n",
    "\n",
    "df_train['tot5'] = df_train[product_col_5].sum(axis=1)\n",
    "df_test['tot5'] = df_test[product_col_5].sum(axis=1)\n",
    "#df_train['tot4'] = df_train[product_col_4].sum(axis=1)\n",
    "#df_test['tot4'] = df_test[product_col_4].sum(axis=1)\n",
    "#df_train['tot3'] = df_train[product_col_3].sum(axis=1)\n",
    "#df_test['tot3'] = df_test[product_col_3].sum(axis=1)\n",
    "#df_train['tot2'] = df_train[product_col_2].sum(axis=1)\n",
    "#df_test['tot2'] = df_test[product_col_2].sum(axis=1)\n",
    "#df_train['tot1'] = df_train[product_col_1].sum(axis=1)\n",
    "#df_test['tot1'] = df_test[product_col_1].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in product_col[2:]:\n",
    "    df_train[col+'_past'] = (df_train[col+'_5']+df_train[col+'_4']+df_train[col+'_3']+df_train[col+'_2']+df_train[col+'_1'])/5\n",
    "    df_test[col+'_past'] = (df_test[col+'_5']+df_test[col+'_4']+df_test[col+'_3']+df_test[col+'_2']+df_test[col+'_1'])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pro in product_col[2:]:\n",
    "    df_train[pro+'_past'] = df_train[pro+'_past']*(1-df_train[pro+'_5'])\n",
    "    df_test[pro+'_past'] = df_test[pro+'_past']*(1-df_test[pro+'_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in product_col[2:]:\n",
    "    for month in range(2,6):\n",
    "        df_train[col+'_'+str(month)+'_diff'] = df_train[col+'_'+str(month)] - df_train[col+'_'+str(month-1)]\n",
    "        df_test[col+'_'+str(month)+'_diff'] = df_test[col+'_'+str(month)] - df_test[col+'_'+str(month-1)]\n",
    "        df_train[col+'_'+str(month)+'_add'] = df_train[col+'_'+str(month)+'_diff'].apply(lambda x: max(x,0))\n",
    "        df_test[col+'_'+str(month)+'_add'] = df_test[col+'_'+str(month)+'_diff'].apply(lambda x: max(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_col_5_diff = [col for col in df_train.columns if '5_diff' in col]\n",
    "product_col_4_diff = [col for col in df_train.columns if '4_diff' in col]\n",
    "product_col_3_diff = [col for col in df_train.columns if '3_diff' in col]\n",
    "product_col_2_diff = [col for col in df_train.columns if '2_diff' in col]\n",
    "\n",
    "product_col_5_add = [col for col in df_train.columns if '5_add' in col]\n",
    "product_col_4_add = [col for col in df_train.columns if '4_add' in col]\n",
    "product_col_3_add = [col for col in df_train.columns if '3_add' in col]\n",
    "product_col_2_add = [col for col in df_train.columns if '2_add' in col]\n",
    "\n",
    "product_col_all_diff = [col for col in df_train.columns if '_diff' in col]\n",
    "product_col_all_add = [col for col in df_train.columns if '_add' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['tot5_add'] = df_train[product_col_5_add].sum(axis=1)\n",
    "df_test['tot5_add'] = df_test[product_col_5_add].sum(axis=1)\n",
    "df_train['tot4_add'] = df_train[product_col_4_add].sum(axis=1)\n",
    "df_test['tot4_add'] = df_test[product_col_4_add].sum(axis=1)\n",
    "df_train['tot3_add'] = df_train[product_col_3_add].sum(axis=1)\n",
    "df_test['tot3_add'] = df_test[product_col_3_add].sum(axis=1)\n",
    "df_train['tot2_add'] = df_train[product_col_2_add].sum(axis=1)\n",
    "df_test['tot2_add'] = df_test[product_col_2_add].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "45671/45671 [==============================] - 2s - loss: 1.1865 - categorical_accuracy: 0.6154     \n",
      "Epoch 2/150\n",
      "45671/45671 [==============================] - 2s - loss: 1.0665 - categorical_accuracy: 0.6396     \n",
      "Epoch 3/150\n",
      "45671/45671 [==============================] - 2s - loss: 1.0419 - categorical_accuracy: 0.6434     \n",
      "Epoch 4/150\n",
      "45671/45671 [==============================] - 2s - loss: 1.0278 - categorical_accuracy: 0.6449     \n",
      "Epoch 5/150\n",
      "45671/45671 [==============================] - 2s - loss: 1.0180 - categorical_accuracy: 0.6479     \n",
      "Epoch 6/150\n",
      "45671/45671 [==============================] - 2s - loss: 1.0107 - categorical_accuracy: 0.6475     \n",
      "Epoch 7/150\n",
      "45671/45671 [==============================] - 2s - loss: 1.0048 - categorical_accuracy: 0.6481     \n",
      "Epoch 8/150\n",
      "45671/45671 [==============================] - 2s - loss: 1.0003 - categorical_accuracy: 0.6495     \n",
      "Epoch 9/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9963 - categorical_accuracy: 0.6496     \n",
      "Epoch 10/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9925 - categorical_accuracy: 0.6515     \n",
      "Epoch 11/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9897 - categorical_accuracy: 0.6498     \n",
      "Epoch 12/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9871 - categorical_accuracy: 0.6524     \n",
      "Epoch 13/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9846 - categorical_accuracy: 0.6522     \n",
      "Epoch 14/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9826 - categorical_accuracy: 0.6519     \n",
      "Epoch 15/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9806 - categorical_accuracy: 0.6531     \n",
      "Epoch 16/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9789 - categorical_accuracy: 0.6514     \n",
      "Epoch 17/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9771 - categorical_accuracy: 0.6529     \n",
      "Epoch 18/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9755 - categorical_accuracy: 0.6542     \n",
      "Epoch 19/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9741 - categorical_accuracy: 0.6544     \n",
      "Epoch 20/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9727 - categorical_accuracy: 0.6537     \n",
      "Epoch 21/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9715 - categorical_accuracy: 0.6531     \n",
      "Epoch 22/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9702 - categorical_accuracy: 0.6542     \n",
      "Epoch 23/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9688 - categorical_accuracy: 0.6541     \n",
      "Epoch 24/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9678 - categorical_accuracy: 0.6551     \n",
      "Epoch 25/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9666 - categorical_accuracy: 0.6554     \n",
      "Epoch 26/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9655 - categorical_accuracy: 0.6547     \n",
      "Epoch 27/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9644 - categorical_accuracy: 0.6561     \n",
      "Epoch 28/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9637 - categorical_accuracy: 0.6537     \n",
      "Epoch 29/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9627 - categorical_accuracy: 0.6553     \n",
      "Epoch 30/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9619 - categorical_accuracy: 0.6565     \n",
      "Epoch 31/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9609 - categorical_accuracy: 0.6557     \n",
      "Epoch 32/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9602 - categorical_accuracy: 0.6562     \n",
      "Epoch 33/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9594 - categorical_accuracy: 0.6552     \n",
      "Epoch 34/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9586 - categorical_accuracy: 0.6557     \n",
      "Epoch 35/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9578 - categorical_accuracy: 0.6570     \n",
      "Epoch 36/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9571 - categorical_accuracy: 0.6588     \n",
      "Epoch 37/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9562 - categorical_accuracy: 0.6584     \n",
      "Epoch 38/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9557 - categorical_accuracy: 0.6560     \n",
      "Epoch 39/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9550 - categorical_accuracy: 0.6575     \n",
      "Epoch 40/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9542 - categorical_accuracy: 0.6579     \n",
      "Epoch 41/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9537 - categorical_accuracy: 0.6577     \n",
      "Epoch 42/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9531 - categorical_accuracy: 0.6584     \n",
      "Epoch 43/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9524 - categorical_accuracy: 0.6580     \n",
      "Epoch 44/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9519 - categorical_accuracy: 0.6573     \n",
      "Epoch 45/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9512 - categorical_accuracy: 0.6580     \n",
      "Epoch 46/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9506 - categorical_accuracy: 0.6577     \n",
      "Epoch 47/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9501 - categorical_accuracy: 0.6578     \n",
      "Epoch 48/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9495 - categorical_accuracy: 0.6574     \n",
      "Epoch 49/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9489 - categorical_accuracy: 0.6588     \n",
      "Epoch 50/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9484 - categorical_accuracy: 0.6595     \n",
      "Epoch 51/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9480 - categorical_accuracy: 0.6594     \n",
      "Epoch 52/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9475 - categorical_accuracy: 0.6589     \n",
      "Epoch 53/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9469 - categorical_accuracy: 0.6588     \n",
      "Epoch 54/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9464 - categorical_accuracy: 0.6579     \n",
      "Epoch 55/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9460 - categorical_accuracy: 0.6586     \n",
      "Epoch 56/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9455 - categorical_accuracy: 0.6593     \n",
      "Epoch 57/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9451 - categorical_accuracy: 0.6584     \n",
      "Epoch 58/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9446 - categorical_accuracy: 0.6585     \n",
      "Epoch 59/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9441 - categorical_accuracy: 0.6593     \n",
      "Epoch 60/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9437 - categorical_accuracy: 0.6593     \n",
      "Epoch 61/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9432 - categorical_accuracy: 0.6597     \n",
      "Epoch 62/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9428 - categorical_accuracy: 0.6595     \n",
      "Epoch 63/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9424 - categorical_accuracy: 0.6593     \n",
      "Epoch 64/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9419 - categorical_accuracy: 0.6604     \n",
      "Epoch 65/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9417 - categorical_accuracy: 0.6586     \n",
      "Epoch 66/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9412 - categorical_accuracy: 0.6598     \n",
      "Epoch 67/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9407 - categorical_accuracy: 0.6597     \n",
      "Epoch 68/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9404 - categorical_accuracy: 0.6596     \n",
      "Epoch 69/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9399 - categorical_accuracy: 0.6596     \n",
      "Epoch 70/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9396 - categorical_accuracy: 0.6597     \n",
      "Epoch 71/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9393 - categorical_accuracy: 0.6589     \n",
      "Epoch 72/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9389 - categorical_accuracy: 0.6606     \n",
      "Epoch 73/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9385 - categorical_accuracy: 0.6588     \n",
      "Epoch 74/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9382 - categorical_accuracy: 0.6612     \n",
      "Epoch 75/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9377 - categorical_accuracy: 0.6602     \n",
      "Epoch 76/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9374 - categorical_accuracy: 0.6596     \n",
      "Epoch 77/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9371 - categorical_accuracy: 0.6600     \n",
      "Epoch 78/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9367 - categorical_accuracy: 0.6604     \n",
      "Epoch 79/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9363 - categorical_accuracy: 0.6609     \n",
      "Epoch 80/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9361 - categorical_accuracy: 0.6609     \n",
      "Epoch 81/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9357 - categorical_accuracy: 0.6615     \n",
      "Epoch 82/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9353 - categorical_accuracy: 0.6597     \n",
      "Epoch 83/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9350 - categorical_accuracy: 0.6617     \n",
      "Epoch 84/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9347 - categorical_accuracy: 0.6603     \n",
      "Epoch 85/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9345 - categorical_accuracy: 0.6607     \n",
      "Epoch 86/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9341 - categorical_accuracy: 0.6597     \n",
      "Epoch 87/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9338 - categorical_accuracy: 0.6603     \n",
      "Epoch 88/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9335 - categorical_accuracy: 0.6604     \n",
      "Epoch 89/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9331 - categorical_accuracy: 0.6601     \n",
      "Epoch 90/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9329 - categorical_accuracy: 0.6591     \n",
      "Epoch 91/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9326 - categorical_accuracy: 0.6603     \n",
      "Epoch 92/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9324 - categorical_accuracy: 0.6614     \n",
      "Epoch 93/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9320 - categorical_accuracy: 0.6608     \n",
      "Epoch 94/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9317 - categorical_accuracy: 0.6606     \n",
      "Epoch 95/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9314 - categorical_accuracy: 0.6604     \n",
      "Epoch 96/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9312 - categorical_accuracy: 0.6616     \n",
      "Epoch 97/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9309 - categorical_accuracy: 0.6624     \n",
      "Epoch 98/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9305 - categorical_accuracy: 0.6607     \n",
      "Epoch 99/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9304 - categorical_accuracy: 0.6606     \n",
      "Epoch 100/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9301 - categorical_accuracy: 0.6613     \n",
      "Epoch 101/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9298 - categorical_accuracy: 0.6611     \n",
      "Epoch 102/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9295 - categorical_accuracy: 0.6614     \n",
      "Epoch 103/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9292 - categorical_accuracy: 0.6613     \n",
      "Epoch 104/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9291 - categorical_accuracy: 0.6614     \n",
      "Epoch 105/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9286 - categorical_accuracy: 0.6620     \n",
      "Epoch 106/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9285 - categorical_accuracy: 0.6605     \n",
      "Epoch 107/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9282 - categorical_accuracy: 0.6606     \n",
      "Epoch 108/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9280 - categorical_accuracy: 0.6624     \n",
      "Epoch 109/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9277 - categorical_accuracy: 0.6627     \n",
      "Epoch 110/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9274 - categorical_accuracy: 0.6620     \n",
      "Epoch 111/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9273 - categorical_accuracy: 0.6609     \n",
      "Epoch 112/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9269 - categorical_accuracy: 0.6616     \n",
      "Epoch 113/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9268 - categorical_accuracy: 0.6613     \n",
      "Epoch 114/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9266 - categorical_accuracy: 0.6628     \n",
      "Epoch 115/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9263 - categorical_accuracy: 0.6625     \n",
      "Epoch 116/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9261 - categorical_accuracy: 0.6620     \n",
      "Epoch 117/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9259 - categorical_accuracy: 0.6627     \n",
      "Epoch 118/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9257 - categorical_accuracy: 0.6628     \n",
      "Epoch 119/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9254 - categorical_accuracy: 0.6630     \n",
      "Epoch 120/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9252 - categorical_accuracy: 0.6616     \n",
      "Epoch 121/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9250 - categorical_accuracy: 0.6620     \n",
      "Epoch 122/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9248 - categorical_accuracy: 0.6621     \n",
      "Epoch 123/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9244 - categorical_accuracy: 0.6623     \n",
      "Epoch 124/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9243 - categorical_accuracy: 0.6619     \n",
      "Epoch 125/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9241 - categorical_accuracy: 0.6632     \n",
      "Epoch 126/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9239 - categorical_accuracy: 0.6625     \n",
      "Epoch 127/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9236 - categorical_accuracy: 0.6628     \n",
      "Epoch 128/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9234 - categorical_accuracy: 0.6625     \n",
      "Epoch 129/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9232 - categorical_accuracy: 0.6627     \n",
      "Epoch 130/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9230 - categorical_accuracy: 0.6620     \n",
      "Epoch 131/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9229 - categorical_accuracy: 0.6626     \n",
      "Epoch 132/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9226 - categorical_accuracy: 0.6629     \n",
      "Epoch 133/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9224 - categorical_accuracy: 0.6633     \n",
      "Epoch 134/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9223 - categorical_accuracy: 0.6618     \n",
      "Epoch 135/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9219 - categorical_accuracy: 0.6636     \n",
      "Epoch 136/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9219 - categorical_accuracy: 0.6617     \n",
      "Epoch 137/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9216 - categorical_accuracy: 0.6622     \n",
      "Epoch 138/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9214 - categorical_accuracy: 0.6623     \n",
      "Epoch 139/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9212 - categorical_accuracy: 0.6620     \n",
      "Epoch 140/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9211 - categorical_accuracy: 0.6633     \n",
      "Epoch 141/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9208 - categorical_accuracy: 0.6628     \n",
      "Epoch 142/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9206 - categorical_accuracy: 0.6632     \n",
      "Epoch 143/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9204 - categorical_accuracy: 0.6633     \n",
      "Epoch 144/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9202 - categorical_accuracy: 0.6628     \n",
      "Epoch 145/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9201 - categorical_accuracy: 0.6626     \n",
      "Epoch 146/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9199 - categorical_accuracy: 0.6626     \n",
      "Epoch 147/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9197 - categorical_accuracy: 0.6627     \n",
      "Epoch 148/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9195 - categorical_accuracy: 0.6636     \n",
      "Epoch 149/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9192 - categorical_accuracy: 0.6642     \n",
      "Epoch 150/150\n",
      "45671/45671 [==============================] - 2s - loss: 0.9190 - categorical_accuracy: 0.6628     \n"
     ]
    }
   ],
   "source": [
    "cols = list(df_train.drop(['target','ncodpers']+product_col_all_diff+product_col_all_add, 1).columns.values)\n",
    "\n",
    "id_preds = defaultdict(list)\n",
    "ids = df_test['ncodpers'].values\n",
    "\n",
    "# predict model \n",
    "y_train = pd.get_dummies(df_train['target'].astype(int))\n",
    "x_train = df_train[cols]\n",
    "    \n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_dim=len(cols), init='uniform', activation='relu'))\n",
    "model.add(Dense(22, init='uniform', activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['categorical_accuracy'])\n",
    "\n",
    "#model.fit(x_train.as_matrix(), y_train.as_matrix(), validation_split=0.2, nb_epoch=150, batch_size=10)\n",
    "model.fit(x_train.as_matrix(), y_train.as_matrix(), nb_epoch=150, batch_size=10)\n",
    "\n",
    "x_test = df_test[cols]\n",
    "x_test = x_test.fillna(0) \n",
    "        \n",
    "p_test = model.predict(x_test.as_matrix())\n",
    "        \n",
    "for id, p in zip(ids, p_test):\n",
    "    #id_preds[id] = list(p)\n",
    "    id_preds[id] = [0,0] + list(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Product Ranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_list = df_train[product_col_5].sum(axis=0)/(df_train[product_col_5].sum(axis=0).sum())\n",
    "\n",
    "id_preds2 = {}\n",
    "for row in df_test.values:\n",
    "    id = row[0]\n",
    "    id_preds2[id] = [0,0]+ list(product_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fraction = 0.9\n",
    "id_preds_combined = {}\n",
    "\n",
    "for uid, p in id_preds.items():\n",
    "    id_preds_combined[uid] = fraction*np.asarray(id_preds[uid]) + (1-fraction)*np.asarray(id_preds2[uid])\n",
    "    \n",
    "id_preds = id_preds_combined    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_recent =  pd.read_csv('cleaned_data/df_recent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check if customer already have each product or not. \n",
    "already_active = {}\n",
    "for row in df_recent.values:\n",
    "    row = list(row)\n",
    "    id = row.pop(0)\n",
    "    active = [c[0] for c in zip(tuple(product_col), row) if c[1] > 0]\n",
    "    already_active[id] = active\n",
    "\n",
    "# add 7 products(that user don't have yet), higher probability first -> train_pred   \n",
    "train_preds = {}\n",
    "for id, p in id_preds.items():\n",
    "    preds = [i[0] for i in sorted([i for i in zip(tuple(product_col), p) if i[0] not in already_active[id]],\n",
    "                                  key=lambda i:i [1], \n",
    "                                  reverse=True)[:7]]\n",
    "    train_preds[id] = preds\n",
    "    \n",
    "test_preds = []\n",
    "for row in sample.values:\n",
    "    id = row[0]\n",
    "    p = train_preds[id]\n",
    "    test_preds.append(' '.join(p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929615, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample['added_products'] = test_preds\n",
    "sample.to_csv('output/Keras1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Validation score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras1 loss: 0.9968\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
