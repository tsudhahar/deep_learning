{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "train, dev = train_test_split(data, test_size=0.25,random_state=0, stratify=data['label'])\n",
    "print(train.shape, dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train.iloc[:, 0].as_matrix()\n",
    "Y_train = np.eye(10, dtype='float32')[Y_train] \n",
    "#it's imp to specify dtype, as default is float64, but placeholder expects float32.\n",
    "X_train = train.iloc[:,1:].as_matrix().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1057\n",
    "img = X_train[index].reshape(28, 28)\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_dev = dev.iloc[:, 0].as_matrix()\n",
    "Y_dev = np.eye(10, dtype='float32')[Y_dev]\n",
    "X_dev = dev.iloc[:,1:].as_matrix().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('test.csv').as_matrix().astype('float32')\n",
    "X_test = np.multiply(X_test, 1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.multiply(X_train, 1.0/255.0)\n",
    "X_dev = np.multiply(X_dev, 1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(mnist.train.images.shape, mnist.test.images.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_batch(initial, batch_size, X, Y):\n",
    "    i = initial * batch_size\n",
    "    j = i + batch_size\n",
    "    return X[i:j], Y[i:j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, _num_epochs):\n",
    "        # set hyperparameters\n",
    "        self.learning_rate = 0.0001\n",
    "        self.minibatch_size = 100 #check X_train and X_dev size before changing this\n",
    "        self.num_epochs = _num_epochs\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            # initialize placeholders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784], name='X')\n",
    "            self.Y = tf.placeholder(tf.int32, [None, 10], name='Y')\n",
    "            self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "            # initialize weights\n",
    "            self.W1 = tf.get_variable('W1', [5, 5, 1, 32], \n",
    "                                      initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "            self.b1 = tf.Variable(tf.constant(0., shape=[32]), name='b1')\n",
    "            self.W2 = tf.get_variable('W2', [5, 5, 32, 64], \n",
    "                                      initializer= tf.contrib.layers.xavier_initializer(seed=0))\n",
    "            self.b2 = tf.Variable(tf.constant(0., shape=[64]), name='b2')\n",
    "            self.W3 = tf.get_variable('W3', [7 * 7 * 64, 1024], \n",
    "                                      initializer= tf.contrib.layers.xavier_initializer(seed=0))\n",
    "            self.b3 = tf.Variable(tf.constant(0., shape=[1024]), name='b3')\n",
    "            self.W4 = tf.get_variable('W4', [1024, 10], \n",
    "                                      initializer= tf.contrib.layers.xavier_initializer(seed=0))\n",
    "            self.b4 = tf.Variable(tf.constant(0., shape=[10]), name='b4')\n",
    "            # forward propogation\n",
    "            self.x_image = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "\n",
    "            self.Z1 = tf.nn.conv2d(self.x_image, self.W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.A1 = tf.nn.relu(self.Z1 + self.b1)\n",
    "            self.h_pool1 = tf.nn.max_pool(self.A1, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "            self.Z2 = tf.nn.conv2d(self.h_pool1, self.W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.A2 = tf.nn.relu(self.Z2 + self.b2)\n",
    "            self.h_pool2 = tf.nn.max_pool(self.A2, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "            self.h_pool2_flat = tf.reshape(self.h_pool2, [-1, 7*7*64])\n",
    "            self.h_fc1 = tf.nn.relu(tf.matmul(self.h_pool2_flat, self.W3) + self.b3)\n",
    "\n",
    "            self.h_fc1_drop = tf.nn.dropout(self.h_fc1, self.keep_prob)\n",
    "            self.Y_conv = tf.matmul(self.h_fc1_drop, self.W4) + self.b4\n",
    "\n",
    "            # cost computation\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                                                                    logits=self.Y_conv,\n",
    "                                                                    labels=self.Y), \n",
    "                                                                   name='cost')\n",
    "            # optimizer\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n",
    "            # accuracy prediction\n",
    "            self.correct_prediction = tf.equal(tf.argmax(self.Y, 1), tf.argmax(self.Y_conv, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "            self.saver = tf.train.Saver()\n",
    "            self.sess = tf.Session(config=config, graph=self.graph)\n",
    "#             writer = tf.summary.FileWriter(\"output\", model.sess.graph)\n",
    "#             writer.close()\n",
    "\n",
    "        \n",
    "    def train(self, X_train, Y_train, X_dev, Y_dev, X_test):\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        costs_epoch_wise = []\n",
    "        costs = []\n",
    "        num_minibatches = X_train.shape[0] // self.minibatch_size\n",
    "        for epoch in range(self.num_epochs+1):\n",
    "            epoch_cost = 0 \n",
    "            for initial in range(num_minibatches):\n",
    "                batch_xs, batch_ys = get_next_batch(initial, self.minibatch_size,\n",
    "                                                    X_train, Y_train)\n",
    "                _, c = self.sess.run([self.optimizer, self.cost], feed_dict={\n",
    "                                                                    self.X: batch_xs,\n",
    "                                                                   self.Y: batch_ys,\n",
    "                                                                  self.keep_prob:0.5})\n",
    "                epoch_cost += c\n",
    "                costs.append(c/num_minibatches)\n",
    "            epoch_cost /= num_minibatches\n",
    "            costs_epoch_wise.append(epoch_cost)\n",
    "            if(epoch%5==0): print('Epoch:', epoch, 'Cost', epoch_cost)\n",
    "\n",
    "        plt.plot(np.squeeze(costs[300:]))\n",
    "        plt.show()\n",
    "        plt.plot(np.squeeze(costs_epoch_wise[5:]))\n",
    "        plt.show()\n",
    "\n",
    "        train_accuracy = self.get_accuracy(X_train, Y_train) \n",
    "\n",
    "        dev_accuracy = self.get_accuracy(X_dev, Y_dev) \n",
    "\n",
    "        mnist_test_accuracy = self.get_accuracy(mnist.test.images, mnist.test.labels) \n",
    "\n",
    "        print('Train set accuracy %0.4f' % train_accuracy)\n",
    "        print('Dev set accuracy %0.4f' % dev_accuracy)\n",
    "        print('mnist test accuracy %g' % mnist_test_accuracy)\n",
    "\n",
    "        Y_predicted = self.predict(X_test)\n",
    "        return np.squeeze(Y_predicted).astype('int')\n",
    "        \n",
    "    def get_accuracy(self, X_data, Y_data):\n",
    "        acc = 0\n",
    "        num_minibatches = X_data.shape[0] // self.minibatch_size\n",
    "        for initial in range(num_minibatches):\n",
    "            batch_xs, batch_ys = get_next_batch(initial, self.minibatch_size, X_data, Y_data)\n",
    "            acc += self.sess.run(self.accuracy, feed_dict={self.X:batch_xs, self.Y:batch_ys,\n",
    "                                                           self.keep_prob:1.0})\n",
    "\n",
    "        return acc/num_minibatches\n",
    "\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        m = X_test.shape[0]\n",
    "        Y_predicted = np.random.randn(m,1)\n",
    "        for k in range(0, m//500):\n",
    "            i = k * 500\n",
    "            j = i + 500\n",
    "            Y_predicted[i:j, 0] = self.sess.run(tf.argmax(self.Y_conv, 1), feed_dict = {\n",
    "                                                                    self.X: X_test[i:j],\n",
    "                                                                    self.keep_prob:1.0})\n",
    "        return np.squeeze(Y_predicted)\n",
    "\n",
    "\n",
    "    def get_mislabeled(self, X_data, Y_data):\n",
    "        Y_predicted = self.predict(X_data)\n",
    "        mistakes = tf.not_equal(tf.argmax(Y_data, 1), tf.argmax(self.Y_predicted, 1))\n",
    "        indices = [x for x,y in mistakes if y==True]\n",
    "        return indices\n",
    "        \n",
    "    def restore_model(self, model_path):\n",
    "        self.saver.restore(self.sess, model_path)\n",
    "        print('Model restored from %s' % model_path)\n",
    "        \n",
    "    def save_model(self, model_path):\n",
    "        self.saver.save(self.sess, model_path)\n",
    "        print('Model saved at %s' % model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "num_epochs = 50\n",
    "model = Model(num_epochs)\n",
    "Y_predicted = model.train(X_train, Y_train, X_dev, Y_dev, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'models/e50cpu.ckpt'\n",
    "# model.restore_model(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on kaggle dev data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mistakes(Y_data, Y_data_prediction):\n",
    "    mistakes = np.not_equal(np.argmax(Y_data, 1), Y_data_prediction)\n",
    "    indices = [x for x,y in enumerate(mistakes) if y==True]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_prediction = model.predict(X_train)\n",
    "train_mistaken_indices = get_mistakes(Y_train, Y_train_prediction)\n",
    "Y_dev_prediction = model.predict(X_dev)\n",
    "dev_mistaken_indices = get_mistakes(Y_dev, Y_dev_prediction)\n",
    "\n",
    "print('Total mislabeled images in Train set', len(train_mistaken_indices))\n",
    "print('Total mislabeled images in dev set', len(dev_mistaken_indices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model analysis\n",
    "\n",
    "5 Epocs, CPU compute-2\n",
    "   \n",
    "    Total mislabeld images in Train set 225\n",
    "    Total mislabeld images in dev set 167\n",
    "    \n",
    "50 Epochs, CPU compute-2\n",
    "\n",
    "    Train set accuracy 0.9997\n",
    "    Dev set accuracy 0.9890\n",
    "    mnist test accuracy 0.9953\n",
    "    Epoch: 50 Cost 0.00279164741919\n",
    "\n",
    "    CPU times: user 2h 45min 4s, sys: 7min 40s, total: 2h 52min 44s\n",
    "    Wall time: 11min 42s\n",
    "    Total mislabeld images in Train set 10\n",
    "    Total mislabeld images in dev set 115    \n",
    "    model: models/e50cpu.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_path = model.saver.save(model.sess, \"models/e50cpu.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_img(index, X_data, Y_data, predicted_Y_data):\n",
    "    pixels = X_data[index]\n",
    "    label = np.argmax(Y_data[index])\n",
    "    plabel = int(predicted_Y_data[index])\n",
    "    # Reshape the array into 28 x 28 array (2-dimensional array)\n",
    "    pixels = pixels.reshape((28, 28))\n",
    "\n",
    "    # Plot\n",
    "    plt.title('Label is {}, predicted {}'.format(label, plabel), color='b')\n",
    "    plt.imshow(pixels, cmap=cm.binary)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_all(indices, X_data, Y_data, predicted_Y_data):\n",
    "    plt.figure(figsize=(100, 100))\n",
    "    rows, cols = int(np.ceil(len(indices)/10)), 10\n",
    "    for i in range(rows * cols):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        try:\n",
    "            j = indices[i]\n",
    "            img = np.reshape(X_data[j], (28, 28))\n",
    "            label = np.argmax(Y_data[j])\n",
    "            plabel = int(predicted_Y_data[j])\n",
    "            plt.imshow(img, cmap=cm.binary)\n",
    "            plt.title('{}, {}'.format(label, plabel), color='b', fontsize=100)\n",
    "            plt.axis('off')\n",
    "        except:\n",
    "            pass\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig('cifar_examples.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.choice(train_mistaken_indices)\n",
    "plot_img(index, X_train, Y_train, Y_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_mistaken_indices:\n",
    "    plot_img(i, X_train, Y_train, Y_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_all(dev_mistaken_indices, X_dev, Y_dev, Y_dev_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('submission-cnn.csv', 'w') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['ImageId', 'Label'])\n",
    "#     for i in range(Y_predicted.shape[0]):\n",
    "#         writer.writerow([i+1, Y_predicted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
