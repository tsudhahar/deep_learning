{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "# sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "train, dev = train_test_split(data, test_size=0.2,random_state=0, stratify=data['label'])\n",
    "print(train.shape, dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train.iloc[:, 0].as_matrix()\n",
    "Y_train = np.eye(10, dtype='float32')[Y_train] \n",
    "#it's imp to specify dtype, as default is float64, but placeholder expects float32.\n",
    "X_train = train.iloc[:,1:].as_matrix().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1057\n",
    "img = X_train[index].reshape(28, 28)\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_dev = dev.iloc[:, 0].as_matrix()\n",
    "Y_dev = np.eye(10, dtype='float32')[Y_dev]\n",
    "X_dev = dev.iloc[:,1:].as_matrix().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('test.csv').as_matrix().astype('float32')\n",
    "X_test = np.multiply(X_test, 1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.multiply(X_train, 1.0/255.0)\n",
    "X_dev = np.multiply(X_dev, 1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_dev.shape, Y_dev.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_batch(initial, batch_size, X, Y):\n",
    "    i = initial * batch_size\n",
    "    j = i + batch_size\n",
    "    return X[i:j], Y[i:j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placholders():\n",
    "    X = tf.placeholder(tf.float32, [None, 784], name='X')\n",
    "    Y = tf.placeholder(tf.int32, [None, 10], name='Y')\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    W1 = tf.get_variable('W1', [5, 5, 1, 32], initializer= tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable('W2', [5, 5, 32, 64], initializer= tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    return (W1, W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propogation(X, parameters):\n",
    "    W1, W2 = parameters\n",
    "    X = tf.reshape(X, [-1, 28, 28, 1])\n",
    "\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding='SAME')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, num_outputs=1024)\n",
    "    \n",
    "    Z4 = tf.contrib.layers.fully_connected(Z3, num_outputs=10, activation_fn=None)\n",
    "    \n",
    "    return Z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y), name='cost')\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_dev, Y_dev, X_test, learning_rate, num_epochs, \n",
    "                                                      minibatch_size):\n",
    "    X, Y = create_placholders()\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propogation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    adam_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Z3, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    m = X_train.shape[0]\n",
    "    costs = []\n",
    "    num_minibatches = m // minibatch_size\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init)        \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0 \n",
    "            for initial in range(num_minibatches):\n",
    "                batch_xs, batch_ys = get_next_batch(initial, minibatch_size, X_train, Y_train)\n",
    "                _, c = sess.run([adam_optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "                epoch_cost += c\n",
    "            epoch_cost /= num_minibatches\n",
    "            costs.append(epoch_cost)\n",
    "            print('Epoch:', epoch, 'Cost', epoch_cost)\n",
    "\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.show()\n",
    "\n",
    "        acc = 0\n",
    "        for initial in range(num_minibatches):\n",
    "            batch_xs, batch_ys = get_next_batch(initial, minibatch_size, X_train, Y_train)\n",
    "            acc += sess.run(accuracy, feed_dict={X:batch_xs, Y:batch_ys})\n",
    "\n",
    "        train_accuracy = acc/num_minibatches\n",
    "        dev_accuracy = sess.run(accuracy, feed_dict={X:X_dev, Y:Y_dev})\n",
    "        \n",
    "        print('Train set accuracy', train_accuracy)\n",
    "        print('Dev set accuracy', dev_accuracy)\n",
    "        \n",
    "        m = X_test.shape[0]\n",
    "        Y_predicted = np.random.randn(m,1)\n",
    "        for k in range(0, m//1000):\n",
    "            i = k*1000\n",
    "            j = i+1000\n",
    "            Y_predicted[i:j, 0] = sess.run(tf.argmax(Z3, 1), feed_dict = {X: X_test[i:j]})\n",
    "\n",
    "    return np.squeeze(Y_predicted).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "learning_rate = 0.01\n",
    "minibatch_size = 1000\n",
    "num_epochs = 14\n",
    "Y_predicted = model(X_train, Y_train, X_dev, Y_dev, X_test, learning_rate, num_epochs, minibatch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on kaggle dev data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission-cnn.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['ImageId', 'Label'])\n",
    "    for i in range(Y_predicted.shape[0]):\n",
    "        writer.writerow([i+1, Y_predicted[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For tensorboard visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writer = tf.summary.FileWriter(\"output\", sess.graph)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#before changing any node in the graph, reset the default graph, run new nodes, reinitialize the session and variables.\n",
    "# to retrain the model, just re-initialise the variables by sess.run(init)\n",
    "# sess.close ? what it actually does?\n",
    "# none of this releases gpu memory\n",
    "# sess.close()\n",
    "# tf.reset_default_graph() # new default graph is created. \n",
    "#parameters contains only W1 and W2.\n",
    "#not other parameters like FC weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     print(sess.run(tf.report_uninitialized_variables()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
