{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model train on account who add more products on June 2015.  Use validation training set from May 2015 and testing on may 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demographic_cols = ['fecha_dato',\n",
    " 'ncodpers','ind_empleado','pais_residencia','sexo','age','fecha_alta','ind_nuevo','antiguedad','indrel',\n",
    " 'indrel_1mes','tiprel_1mes','indresi','indext','conyuemp','canal_entrada','indfall',\n",
    " 'tipodom','cod_prov','ind_actividad_cliente','renta','segmento']\n",
    "\n",
    "notuse = [\"ult_fec_cli_1t\",\"nomprov\"]\n",
    "\n",
    "product_col = [\n",
    " 'ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1',\n",
    " 'ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1',\n",
    " 'ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_plan_fin_ult1',\n",
    " 'ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1','ind_nomina_ult1',\n",
    " 'ind_nom_pens_ult1','ind_recibo_ult1']\n",
    "\n",
    "product_col_prev = []\n",
    "\n",
    "for col in product_col:\n",
    "    product_col_prev.append(col+'_prev')\n",
    "\n",
    "#product_col = product_col[2:]\n",
    "\n",
    "train_cols = demographic_cols + ['target'] + product_col_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rkcosmos/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('cleaned_data/juneExtraMulticlass.csv', usecols=train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rkcosmos/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('cleaned_data/TestSet.csv', usecols = demographic_cols + product_col_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_data(df):\n",
    "    df = df[df['ind_nuevo'] == 0]\n",
    "    df = df[df['antiguedad'] != -999999]\n",
    "    df = df[df['indrel'] == 1]\n",
    "    df = df[df['indresi'] == 'S']\n",
    "    df = df[df['indfall'] == 'N']\n",
    "    df = df[df['tipodom'] == 1]\n",
    "    df = df[df['ind_empleado'] == 'N']\n",
    "    df = df[df['pais_residencia'] == 'ES']\n",
    "    df = df[df['indrel_1mes'] == 1]\n",
    "    df = df[df['tiprel_1mes'] == ('A' or 'I')]\n",
    "    df = df[df['indext'] == 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_data(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unneccessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_column = ['ind_nuevo','indrel','indresi','indfall','tipodom','ind_empleado','pais_residencia','indrel_1mes','indext','conyuemp','fecha_alta','tiprel_1mes']\n",
    "\n",
    "df_train.drop(drop_column, axis=1, inplace = True)\n",
    "df_test.drop(drop_column, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test[\"renta\"]   = pd.to_numeric(df_test[\"renta\"], errors=\"coerce\")\n",
    "unique_prov = df_test[df_test.cod_prov.notnull()].cod_prov.unique()\n",
    "grouped = df_test.groupby(\"cod_prov\")[\"renta\"].median()\n",
    "\n",
    "def impute_renta(df):\n",
    "    df[\"renta\"]   = pd.to_numeric(df[\"renta\"], errors=\"coerce\")       \n",
    "    for cod in unique_prov:\n",
    "        df.loc[df['cod_prov']==cod,['renta']] = df.loc[df['cod_prov']==cod,['renta']].fillna({'renta':grouped[cod]}).values\n",
    "    df.renta.fillna(df_test[\"renta\"].median(), inplace=True)\n",
    "    \n",
    "impute_renta(df_train)\n",
    "impute_renta(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drop_na(df):\n",
    "    df.dropna(axis = 0, subset = ['ind_actividad_cliente'], inplace = True)\n",
    "    \n",
    "drop_na(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert and make dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These column are categories feature, I'll transform them using get_dummy\n",
    "dummy_col = ['sexo','canal_entrada','cod_prov','segmento']\n",
    "dummy_col_select = ['canal_entrada','cod_prov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit = int(0.05 * len(df_train.index))\n",
    "use_dummy_col = {}\n",
    "\n",
    "for col in dummy_col_select:\n",
    "    trainlist = df_train[col].value_counts()\n",
    "    use_dummy_col[col] = []\n",
    "    for i,item in enumerate(trainlist):\n",
    "        if item > limit:\n",
    "            use_dummy_col[col].append(df_train[col].value_counts().index[i])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dummy(df):\n",
    "    for col in dummy_col_select:\n",
    "        for item in df[col].unique(): \n",
    "            if item not in use_dummy_col[col]:\n",
    "                row_index = df[col] == item\n",
    "                df.loc[row_index,col] = np.nan\n",
    "    return pd.get_dummies(df, prefix=dummy_col, columns = dummy_col)\n",
    "    \n",
    "df_train = get_dummy(df_train)\n",
    "df_test = get_dummy(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_age(df):\n",
    "    max_age = 80\n",
    "    df[\"age\"]   = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "    df[\"age\"]   = df['age'].apply(lambda x: round(min(x,max_age)/max_age, 4))\n",
    "    \n",
    "clean_age(df_train)\n",
    "clean_age(df_test)\n",
    "\n",
    "def clean_renta(df):\n",
    "    max_renta = 1000000\n",
    "    df[\"renta\"]   = df['renta'].apply(lambda x: round(min(x,max_renta)/max_renta, 4))        \n",
    "         \n",
    "clean_renta(df_train)\n",
    "clean_renta(df_test)\n",
    "\n",
    "def clean_antigue(df):\n",
    "    max_antigue = 256\n",
    "    df[\"antiguedad\"]   = pd.to_numeric(df[\"antiguedad\"], errors=\"coerce\")\n",
    "    df[\"antiguedad\"] = df['antiguedad'].apply(lambda x: round(min(x,max_antigue)/max_antigue, 4))   \n",
    "\n",
    "clean_antigue(df_train)\n",
    "clean_antigue(df_test)\n",
    "\n",
    "#df_train['tot'] = df_train[product_col_prev].sum(axis=1)\n",
    "#df_test['tot'] = df_test[product_col_prev].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, colsample_bytree=0.9, max_depth= 6, eta=0.05, min_child_weight=2, subsample=0.9, num_rounds=110):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['seed'] = 0\n",
    "    param['silent'] = 0\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['booster'] = 'gbtree'\n",
    "    param['num_class'] = 24\n",
    "    param['colsample_bytree'] = colsample_bytree\n",
    "    param['max_depth'] = max_depth \n",
    "    param['eta'] = eta\n",
    "    param['min_child_weight'] = min_child_weight\n",
    "    param['subsample'] = subsample\n",
    "    num_round = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "    model = xgb.train(plst, xgtrain, num_round)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rkcosmos/anaconda/lib/python3.5/site-packages/pandas/core/frame.py:2762: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cols = list(df_train.drop(['target','ncodpers',\"fecha_dato\"], 1).columns.values)\n",
    "\n",
    "id_preds = defaultdict(list)\n",
    "ids = df_test['ncodpers'].values\n",
    "\n",
    "# predict model \n",
    "y_train = df_train['target']\n",
    "x_train = df_train.drop(['target','ncodpers',\"fecha_dato\"], 1)\n",
    "    \n",
    "clf = runXGB(x_train, y_train)\n",
    "          \n",
    "x_test = df_test[cols]\n",
    "x_test.fillna(0,inplace=True)\n",
    "        \n",
    "d_test = xgb.DMatrix(x_test)\n",
    "p_test = clf.predict(d_test)\n",
    "        \n",
    "for id, p in zip(ids, p_test):\n",
    "    id_preds[id] = list(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_recent =  pd.read_csv('cleaned_data/df_recent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check if customer already have each product or not. \n",
    "already_active = {}\n",
    "for row in df_recent.values:\n",
    "    row = list(row)\n",
    "    id = row.pop(0)\n",
    "    active = [c[0] for c in zip(tuple(product_col), row) if c[1] > 0]\n",
    "    already_active[id] = active\n",
    "\n",
    "# add 7 products(that user don't have yet), higher probability first -> train_pred   \n",
    "train_preds = {}\n",
    "for id, p in id_preds.items():\n",
    "    preds = [i[0] for i in sorted([i for i in zip(tuple(product_col), p) if i[0] not in already_active[id]],\n",
    "                                  key=lambda i:i [1], \n",
    "                                  reverse=True)[:7]]\n",
    "    train_preds[id] = preds\n",
    "    \n",
    "test_preds = []\n",
    "for row in sample.values:\n",
    "    id = row[0]\n",
    "    p = train_preds[id]\n",
    "    test_preds.append(' '.join(p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929615, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample['added_products'] = test_preds\n",
    "sample.to_csv('output/XGBmulticlass.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
